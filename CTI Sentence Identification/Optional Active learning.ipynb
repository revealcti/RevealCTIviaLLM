{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7771884b",
   "metadata": {},
   "source": [
    "<div align='left' ><font size='70'>Setup and function</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016276b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "PKL_FILE = ['', 'full_batch1_big_label_list.pkl']\n",
    "CSV_FILE = 'batch2_onlyvaild.csv'\n",
    "active_learning_target_label = 'FullNegative'\n",
    "BEST_MODEL_DIR = 'clfmodel/2/best_model'\n",
    "ALL_MODEL_DIR = ['clfmodel/2/best_model', 'clfmodel/0/best_model', 'clfmodel/4/best_model']\n",
    "TEXT_HEADER = 'raw_text'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "print('import all DONE!')\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import entropy  # type: ignore\n",
    "from simpletransformers.classification import (  # type: ignore\n",
    "    ClassificationArgs, MultiLabelClassificationModel)\n",
    "\n",
    "os.chdir(r\"/data/V10\")\n",
    "\n",
    "pkl_file = open(PKL_FILE[1], 'rb')\n",
    "big_label_list = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "print(big_label_list)\n",
    "\n",
    "\n",
    "#Functions\n",
    "def add_string_preditcion(inputDF: pd.DataFrame) -> pd.DataFrame:\n",
    "    predict_string = []\n",
    "    for i in inputDF.index:\n",
    "        predict_onehot = ast.literal_eval(inputDF.at[i, 'predict'])\n",
    "        builder_string = \"\"\n",
    "        for j in range(len(predict_onehot)):\n",
    "            if predict_onehot[j] == 1:\n",
    "                if builder_string == '':\n",
    "                    builder_string = big_label_list[j]\n",
    "                else:\n",
    "                    builder_string = builder_string + ', ' + big_label_list[j]\n",
    "        if builder_string == '':\n",
    "            builder_string = 'FullNegative'\n",
    "        #if sum(predict_onehot)>=2:\n",
    "        predict_string.append(builder_string)\n",
    "    inputDF['predict_string'] = predict_string\n",
    "    return inputDF\n",
    "\n",
    "\n",
    "def Uncertainty_Sampling(inputDF: pd.DataFrame) -> pd.DataFrame:\n",
    "    copyDF = copy.deepcopy(inputDF)\n",
    "    copyDF.reset_index(inplace=True, drop=True)\n",
    "    classification_uncertainty = []\n",
    "    classification_margin = []\n",
    "    classification_entropy = []\n",
    "    model_args = {\"silent\": False, }\n",
    "    predict_string_list = inputDF[TEXT_HEADER].values.tolist()\n",
    "    model = MultiLabelClassificationModel(\"roberta\", BEST_MODEL_DIR, args=model_args)\n",
    "    predictions, raw_outputs = model.predict(predict_string_list)\n",
    "    for s in raw_outputs:\n",
    "        classification_uncertainty.append(1 - max(s))\n",
    "        classification_entropy.append(entropy(s))\n",
    "        s.sort()\n",
    "        classification_margin.append(1 - (s[-1] - s[-2]))\n",
    "    predict_string = []\n",
    "    for i in copyDF.index:\n",
    "        predict_onehot = predictions[i]\n",
    "        builder_string = \"\"\n",
    "        for j in range(len(predict_onehot)):\n",
    "            if predict_onehot[j] == 1:\n",
    "                if builder_string == '':\n",
    "                    builder_string = big_label_list[j]\n",
    "                else:\n",
    "                    builder_string = builder_string + ', ' + big_label_list[j]\n",
    "        if builder_string == '':\n",
    "            builder_string = 'FullNegative'\n",
    "        #if sum(predict_onehot)>=2:\n",
    "        predict_string.append(builder_string)\n",
    "    raw_list = raw_outputs.tolist()\n",
    "    copyDF['predict_string'] = predict_string\n",
    "    copyDF['raw_outputs'] = raw_list\n",
    "    copyDF['classification_uncertainty'] = classification_uncertainty\n",
    "    copyDF['classification_margin'] = classification_margin\n",
    "    copyDF['classification_entropy'] = classification_entropy\n",
    "    return copyDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a3db4",
   "metadata": {},
   "source": [
    "<div align='left' ><font size='70'>Active learning </font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077c46e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(CSV_FILE)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "if 'predict' not in list(data.columns):\n",
    "    predict_fill_null = ['Null_predict'] * data.shape[0]\n",
    "    data['predict'] = predict_fill_null\n",
    "else:\n",
    "    data_with_predicted_label = add_string_preditcion(data)\n",
    "    data_with_target_predicted_label = data_with_predicted_label[data_with_predicted_label['predict_string'].str.contains(active_learning_target_label)]\n",
    "    data_with_target_predicted_label.reset_index(inplace=True, drop=True)\n",
    "    data = data_with_target_predicted_label\n",
    "data_with_uncertanty = Uncertainty_Sampling(data)\n",
    "data_with_uncertanty = data_with_uncertanty\n",
    "number_col = ['classification_uncertainty', 'classification_margin','classification_entropy']\n",
    "\n",
    "while True in data_with_uncertanty[TEXT_HEADER].str.contains(\"\\n\").tolist():\n",
    "    data_with_uncertanty = data_with_uncertanty.replace('\\n', '', regex=True)\n",
    "\n",
    "sum_of_total = []\n",
    "product_of_total = []\n",
    "\n",
    "for i in data_with_uncertanty.index:\n",
    "    thesum = 0\n",
    "    for s in number_col:\n",
    "        thesum = thesum + data_with_uncertanty.at[i, s]\n",
    "    sum_of_total.append(thesum)\n",
    "    product = 1\n",
    "    for s in number_col:\n",
    "        product = product * data_with_uncertanty.at[i, s]\n",
    "    product_of_total.append(product)\n",
    "data_with_uncertanty['Sum_of_uncertainty_value'] = sum_of_total\n",
    "data_with_uncertanty['Product_of_uncertainty_value'] = product_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214922c9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Save the result\n",
    "active_learning_target_label = active_learning_target_label.replace(\" \", \"\")\n",
    "finalstr = CSV_FILE.split('.csv')[0] + '_' + active_learning_target_label + '_active_learning.csv'\n",
    "data_with_uncertanty.to_csv(finalstr, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
